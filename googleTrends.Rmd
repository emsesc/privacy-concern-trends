Analyzing before and after trend data
```{r}
library(gtrendsR)

# results_list1 <- list()
# nrow(google_trends_analysis)

# Iterate over each row in google_trends_analysis
for (i in 5:nrow(test2)) {
  # Extract the DMA value from the ith row
  dma <- test2[i, ]$Trends_DMA
  paste(dma)
  
  # Fetch the data using gtrends
  trend_data <- gtrends("library", geo = c(dma), time = "2021-12-01 2024-01-01")
  
  # Store the interest over time data in the results list
  results_list1[[i]] <- trend_data$interest_over_time
}

# combined_df <- do.call(rbind, results_list)
```

Loops
```{r}
library(gtrendsR)

# results_list1 <- list()
# nrow(google_trends_analysis)

# Iterate over each row in google_trends_analysis
for (i in 72:nrow(test2)) {
  # Extract the DMA value from the ith row
  dma <- test2[i, ]$Trends_DMA
  paste(dma)
  
  # Fetch the data using gtrends
  trend_data <- gtrends("library near me", geo = c(dma), time = "2021-12-01 2024-01-01")
  
  # Store the interest over time data in the results list
  results_list1[[i]] <- trend_data$interest_over_time
}

# combined_df <- do.call(rbind, results_list)
```

Attempt 2
```{r}
combined_df <- combined_df %>% 
  select(date, hits, keyword, geo)
  
library(dplyr)

# Convert date column to proper date format in combined_df
combined_df$date <- as.Date(combined_df$date)

# Extract month and year from the date column
combined_df <- combined_df %>%
  mutate(trends_month = as.numeric(format(date, "%m")),
         trends_year = as.numeric(format(date, "%Y")))

# Left join combined_df with google_trends_analysis based on the "geo" column
joined_df <- left_join(combined_df, google_trends_analysis, by = c("geo" = "Trends_DMA"))

# Calculate average hits for the month before and after
hit_change <- joined_df %>%
  distinct() %>%
  mutate(
    prev_month = ifelse(Month == 1, 12, as.numeric(Month) - 1),
    prev_year = ifelse(Month == 1, as.numeric(Year) - 1, as.numeric(Year)),
    next_month = ifelse(Month == 12, 1, as.numeric(Month) + 1),
    next_year = ifelse(Month == 12, as.numeric(Year) + 1, as.numeric(Year)),
    avg_hits_prev_month = ifelse(trends_month == prev_month & trends_year == prev_year, 1, 0),
    avg_hits_next_month = ifelse(trends_month == next_month & trends_year == next_year, 1, 0)
  ) %>%
 select(geo, hits, Year, Month, DMA, STATE, count, avg_hits_prev_month, avg_hits_next_month)

# fix grouping to unique month, year, and DMA commbination
# partisan search terms (ex: lgbtq book vs. sexually explicit book depending on political views), banned books week)

# Print hit_change dataframe
print(hit_change)
# full_join(google_trends_analysis, by = c("geo" = "Trends_DMA"))

avg_hits_prev_month_1_avg <- hit_change %>%
  filter(avg_hits_prev_month == 1) %>%
  group_by(geo, Month, Year, DMA, STATE, count) %>%
  summarise(avg_hits = mean(hits))

avg_hits_next_month_1_avg <- hit_change %>%
  filter(avg_hits_next_month == 1) %>%
  group_by(geo, Month, Year, DMA, STATE, count) %>%
  summarise(avg_hits = mean(hits))

hits_combined_df <- full_join(avg_hits_prev_month_1_avg, avg_hits_next_month_1_avg, by = c("geo", "Month", "Year", "DMA", "STATE", "count"), suffix = c("_prev_month", "_next_month"))
```

* Plot histogram of outcome
* Negative binomial model (for skewed data)

```{r}
libraries_near_me <- read.csv("./outputs/library_near_me_full.csv")
library <- read.csv("./outputs/real-libraries-search.csv")
library_index <- read.csv("./outputs/library_index.csv")

hits_combined_df <- full_join(libraries_near_me, library, by = c("X", "geo", "Month", "Year", "DMA", "STATE", "count")) %>%
  mutate(code = as.numeric(substr(geo, nchar(geo) - 2, nchar(geo)))) %>%
  left_join(library_index, by = "code") %>%
  mutate(avg_hits_next_month = rowSums(select(., starts_with("avg_hits_next_month")), na.rm = TRUE),
         avg_hits_prev_month = rowSums(select(., starts_with("avg_hits_prev_month")), na.rm = TRUE))

hist(hits_combined_df$avg_hits_next_month - hits_combined_df$avg_hits_prev_month, main = "Distribution of Difference of Library Searches", xlab = "Difference in Average Hits (Next Month - Previous Month)", ylab = "Frequency")

# Fit OLS model
ols_model <- lm(avg_hits_next_month - avg_hits_prev_month ~ as.factor(STATE) + count + std_avg_index + num_lib, data = hits_combined_df)

# Summarize the model
summary(ols_model)

plot(ols_model, which = 1)

ols_model <- lm(count ~ num_lib, data = hits_combined_df)

# tidycensus?

# Summarize the model
summary(ols_model)

plot(ols_model, which = 1)
```
Significance in count vs. library search terms
```{r}
# Fit OLS model
ols_model <- lm(avg_hits_next_month - avg_hits_prev_month ~ as.factor(STATE) + count + std_avg_index + num_lib, data = hits_combined_df)

# Summarize the model
summary(ols_model)

plot(ols_model, which = 1)
```

Significance in Num_lib vs. library quality
```{r}
dma_pop <- read.csv("outputs/dma_pop.csv")

test_hits <- hits_combined_df %>% mutate(code = as.numeric(substr(geo, nchar(geo) - 2, nchar(geo))))

test3 <- google_trends_analysis %>% mutate(code = as.numeric(substr(Trends_DMA, nchar(Trends_DMA) - 2, nchar(Trends_DMA)))) %>%
    left_join(library_index, by = "code") %>%
    left_join(dma_pop, by = "code") %>%
    left_join(dma_income, by = "code") %>%
    left_join(test_hits, by = c("Month", "Year", "STATE", "count", "code"))

# Fit OLS model
ols_model <- lm(std_avg_index ~ num_lib + count + tot_income + offset(log(tot_pop)) + avg_hits_next_month, data = test3)

# Summarize the model
summary(ols_model)

plot(ols_model, which = 1)

ols_model <- lm(avg_hits_next_month - avg_hits_prev_month ~ tot_income + tot_pop, data = test3)

# Summarize the model
summary(ols_model)

plot(ols_model, which = 1)

# the more libraries the less book bans???

ols_model <- lm(count ~ num_lib, data = test3)

# Summarize the model
summary(ols_model)

plot(ols_model, which = 1)
```

\